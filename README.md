# ML_Random_Forest

## Explanation
> A Random Forest is an ensemble learning technique primarily used for classification and regression tasks. It builds multiple decision trees and combines their outputs to produce a more accurate and robust prediction.
> It is best with high dimensional dataset. That is dataset with multiple features

## What is Ensemble Learning?
> Ensemble Learning is a machine learning technique where multiple models (referred to as "weak learners" or "base models") are combined to produce a more robust and accurate predictive model. The idea is that by combining diverse models, the ensemble can outperform any individual model.
> It is when you take multiple algorithm or same algorithm multiple time to build a robust model for better predictions

## How Random forest works
> Many predictions are made from each tree say about different 500 predictions are made, nut the final outcome takes the average of all 500 predictions to produce the final one outcome result.

## Advantages of Random Forest
> + Robustness to Overfitting: Reduces overfitting by averaging predictions from multiple trees.
> + Handles Non-linear Relationships: Decision trees in the forest can capture complex patterns in the data.
> + Feature Importance: Provides a measure of feature importance, helping with feature selection.
> + Handles Missing Data: Can handle datasets with missing values effectively.

